# 200 MCQs for Prompt & Context Engineering Exam

Below is a comprehensive set of 200 multiple-choice questions (MCQs) covering the exam topics provided in the "Key Topics Covered" section, including Fundamentals, Configuration Settings, Prompting Techniques, Best Practices & Pitfalls, Testing and Evaluation, Advanced Techniques, Mixture-of-Experts (MoE) & Prompting, Practical Application, Context Engineering Integration, 6-Step Framework, and AI Image Generation (Nano Banana). Each question includes the correct answer and a short explanation, ensuring alignment with the syllabus and the user’s focus on ChatGPT, Gemini, Claude, and Grok, with MoE considerations. The artifact is structured as a markdown README.md file for easy reference.

---

## MCQ 1
**Question:** What is the primary goal of prompt engineering?  
A. Providing relevant documents to ground responses  
B. Crafting clear instructions for desired outputs  
C. Managing the entire context window  
D. Optimizing token usage in agents  

**Answer:** B  
**Short Explanation:** Prompt engineering focuses on crafting clear, specific instructions to elicit desired outputs from LLMs, unlike context engineering, which manages the broader context window.

---

## MCQ 2
**Question:** How do LLMs function as prediction engines?  
A. By understanding human intent  
B. By guessing next tokens based on patterns  
C. By storing complete datasets  
D. By reasoning like humans  

**Answer:** B  
**Short Explanation:** LLMs predict the next token in a sequence based on learned patterns, acting as sophisticated autocomplete systems, not human-like reasoners.

---

## MCQ 3
**Question:** What is a common failure mode of LLMs due to missing information?  
A. Overly long outputs  
B. Hallucinations  
C. Structured outputs  
D. Consistent responses  

**Answer:** B  
**Short Explanation:** Hallucinations occur when LLMs generate incorrect or fabricated information due to insufficient context.

---

## MCQ 4
**Question:** What is the recommended workflow for combining prompt and context engineering?  
A. Ground with context first, then prompt  
B. Prompt first, then ground with context  
C. Use only context without prompts  
D. Avoid context for simple tasks  

**Answer:** B  
**Short Explanation:** Start with a clear prompt to guide behavior, then add context (e.g., retrieved documents) to ground responses for accuracy.

---

## MCQ 5
**Question:** How are LLMs best described?  
A. Human-like reasoning systems  
B. Sophisticated autocomplete systems  
C. Database storage systems  
D. Rule-based engines  

**Answer:** B  
**Short Explanation:** LLMs predict tokens based on patterns, functioning like advanced autocomplete systems, not human-like reasoners.

---

## MCQ 6
**Question:** What does the temperature setting control in LLMs?  
A. Output length  
B. Randomness/creativity  
C. Token limit  
D. Model selection  

**Answer:** B  
**Short Explanation:** Temperature controls randomness: low (0–0.3) for consistency, high (0.8–1) for creativity.

---

## MCQ 7
**Question:** Which configuration is best for a math task?  
A. Temperature 0.9, Top-P 0.99  
B. Temperature 0, Top-P 0.9  
C. Temperature 0.7, Top-K 40  
D. Temperature 0.2, Top-K 100  

**Answer:** B  
**Short Explanation:** Low temperature (0) ensures deterministic, consistent outputs, ideal for math tasks.

---

## MCQ 8
**Question:** What does Top-K sampling do?  
A. Limits predictions to top K likely tokens  
B. Sets a probability threshold  
C. Controls output length  
D. Selects the model  

**Answer:** A  
**Short Explanation:** Top-K sampling restricts predictions to the top K most likely tokens, balancing quality and diversity.

---

## MCQ 9
**Question:** What is the purpose of Top-P (nucleus) sampling?  
A. Limits output to fixed tokens  
B. Considers tokens until a probability threshold  
C. Sets randomness level  
D. Defines context window size  

**Answer:** B  
**Short Explanation:** Top-P sampling includes tokens until their cumulative probability reaches P, allowing dynamic selection.

---

## MCQ 10
**Question:** Which configuration is best for creative writing?  
A. Temperature 0.1, Top-P 0.9  
B. Temperature 0.9, Top-P 0.99  
C. Temperature 0, Top-K 20  
D. Temperature 0.5, Top-K 10  

**Answer:** B  
**Short Explanation:** High temperature (0.9) and Top-P (0.99) encourage diverse, creative outputs suitable for writing.

---

## MCQ 11
**Question:** What is the role of output/token limits in LLMs?  
A. Control response length and cost  
B. Select the model type  
C. Define randomness  
D. Set context window size  

**Answer:** A  
**Short Explanation:** Token limits manage response length and computational cost, critical for efficiency.

---

## MCQ 12
**Question:** Which setting is conservative for factual tasks?  
A. Temperature 0.9, Top-K 40  
B. Temperature 0.1, Top-P 0.9  
C. Temperature 0.7, Top-P 0.95  
D. Temperature 1.0, Top-K 50  

**Answer:** B  
**Short Explanation:** Low temperature (0.1) and moderate Top-P (0.9) ensure consistent, factual outputs.

---

## MCQ 13
**Question:** What is zero-shot prompting?  
A. Providing one example  
B. Direct question without examples  
C. Using 3–5 examples  
D. Assigning a persona  

**Answer:** B  
**Short Explanation:** Zero-shot prompting involves asking a direct question without providing examples.

---

## MCQ 14
**Question:** How many examples are typically used in few-shot prompting?  
A. 1  
B. 3–5  
C. 10  
D. 0  

**Answer:** B  
**Short Explanation:** Few-shot prompting uses 3–5 examples to establish patterns for better outputs.

---

## MCQ 15
**Question:** What does Chain of Thought (CoT) prompting encourage?  
A. Direct answers  
B. Step-by-step reasoning  
C. Multiple outputs  
D. Image generation  

**Answer:** B  
**Short Explanation:** CoT prompts (e.g., “Let’s think step by step”) guide LLMs to reason systematically.

---

## MCQ 16
**Question:** What is the purpose of role prompting?  
A. Set output format  
B. Assign a persona to the LLM  
C. Retrieve external data  
D. Compress context  

**Answer:** B  
**Short Explanation:** Role prompting assigns a specific persona (e.g., “financial advisor”) to guide responses.

---

## MCQ 17
**Question:** In context engineering, the LLM is analogous to what?  
A. RAM  
B. CPU  
C. Disk  
D. Network  

**Answer:** B  
**Short Explanation:** The LLM acts as the CPU, processing the context window as RAM.

---

## MCQ 18
**Question:** What is a key feature of Self-Consistency prompting?  
A. Single output  
B. Multiple reasoning paths, pick common answer  
C. Direct question  
D. Image-based input  

**Answer:** B  
**Short Explanation:** Self-Consistency generates multiple outputs and selects the most common for reliability.

---

## MCQ 19
**Question:** What does ReAct prompting combine?  
A. Reasoning and actions  
B. Multiple examples  
C. Image and text inputs  
D. Context compression  

**Answer:** A  
**Short Explanation:** ReAct combines reasoning and actions (e.g., tool calls) for complex tasks.

---

## MCQ 20
**Question:** What is the purpose of Tree of Thoughts (ToT) prompting?  
A. Direct answers  
B. Branching for complex decisions  
C. Single-step reasoning  
D. Image generation  

**Answer:** B  
**Short Explanation:** ToT explores multiple reasoning branches for complex problem-solving.

---

## MCQ 21
**Question:** Which prompt technique is best for math problems?  
A. Zero-shot  
B. Chain of Thought (CoT)  
C. One-shot  
D. Role prompting  

**Answer:** B  
**Short Explanation:** CoT encourages step-by-step reasoning, ideal for math problems.

---

## MCQ 22
**Question:** What is a best practice for prompt engineering?  
A. Use vague verbs  
B. Overload with constraints  
C. Use positive instructions  
D. Avoid structured formats  

**Answer:** C  
**Short Explanation:** Positive instructions (e.g., “Write formally”) are clearer than negative ones.

---

## MCQ 23
**Question:** What is a common pitfall in prompt engineering?  
A. Using specific verbs  
B. Vague instructions  
C. Structured outputs  
D. Few-shot examples  

**Answer:** B  
**Short Explanation:** Vague instructions lead to unpredictable, messy outputs.

---

## MCQ 24
**Question:** Why should you avoid overloading prompts with constraints?  
A. Improves clarity  
B. Causes confusion  
C. Enhances creativity  
D. Reduces token usage  

**Answer:** B  
**Short Explanation:** Too many constraints confuse the LLM, leading to inconsistent outputs.

---

## MCQ 25
**Question:** What is a recommended practice for complex tasks?  
A. Use single prompts  
B. Break into prompt chains  
C. Avoid examples  
D. Use high temperature  

**Answer:** B  
**Short Explanation:** Prompt chaining breaks complex tasks into manageable steps for better results.

---

## MCQ 26
**Question:** What is a key metric for evaluating prompt outputs?  
A. Token limit  
B. Relevance  
C. Model size  
D. Temperature  

**Answer:** B  
**Short Explanation:** Relevance ensures outputs align with the user’s intent.

---

## MCQ 27
**Question:** What does A/B testing involve in prompt engineering?  
A. Comparing model sizes  
B. Testing different prompt versions  
C. Changing token limits  
D. Adjusting guardrails  

**Answer:** B  
**Short Explanation:** A/B testing compares prompt variations to identify the most effective.

---

## MCQ 28
**Question:** What is a key component of a testing framework for prompts?  
A. Model training  
B. Recording prompt versions  
C. Setting high temperature  
D. Avoiding examples  

**Answer:** B  
**Short Explanation:** Recording prompt versions, goals, and settings tracks performance.

---

## MCQ 29
**Question:** What is a benefit of structured outputs in prompt engineering?  
A. Increases randomness  
B. Enhances usability  
C. Reduces context  
D. Adds ambiguity  

**Answer:** B  
**Short Explanation:** Structured outputs (e.g., JSON) are easier to use and share.

---

## MCQ 30
**Question:** What is a common failure mode in long conversations?  
A. Context rot  
B. Overly short outputs  
C. Perfect recall  
D. Structured responses  

**Answer:** A  
**Short Explanation:** Context rot degrades LLM performance as the context window grows.

---

## MCQ 31
**Question:** What is prompt chaining?  
A. Using a single prompt  
B. Sequential steps for complex tasks  
C. Randomizing outputs  
D. Avoiding examples  

**Answer:** B  
**Short Explanation:** Prompt chaining breaks tasks into sequential steps for clarity.

---

## MCQ 32
**Question:** What is the purpose of multi-modal prompting?  
A. Text-only inputs  
B. Combining text and images  
C. Reducing token usage  
D. Simplifying outputs  

**Answer:** B  
**Short Explanation:** Multi-modal prompting integrates text and images for richer inputs.

---

## MCQ 33
**Question:** In MoE architecture, what selects the experts?  
A. Dense network  
B. Gating network  
C. Full model  
D. Token limit  

**Answer:** B  
**Short Explanation:** The gating network routes inputs to specialized experts in MoE.

---

## MCQ 34
**Question:** What is a benefit of MoE architecture?  
A. Increased memory usage  
B. Efficiency through sparse activation  
C. Slower processing  
D. No specialization  

**Answer:** B  
**Short Explanation:** MoE uses sparse activation for efficient, specialized processing.

---

## MCQ 35
**Question:** What is a drawback of MoE models?  
A. High accuracy  
B. Routing instability  
C. Low token usage  
D. Perfect recall  

**Answer:** B  
**Short Explanation:** Routing instability can cause inconsistent expert selection in MoE.

---

## MCQ 36
**Question:** How should prompts be designed for MoE models?  
A. Use vague terms  
B. Front-load domain-specific signals  
C. High temperature  
D. Avoid examples  

**Answer:** B  
**Short Explanation:** Domain-specific signals activate relevant experts in MoE models.

---

## MCQ 37
**Question:** What temperature is best for MoE model consistency?  
A. 0.9  
B. 0.7  
C. 0.1  
D. 1.0  

**Answer:** C  
**Short Explanation:** Low temperature (0.1) stabilizes expert routing in MoE models.

---

## MCQ 38
**Question:** What is a key element for effective prompts in content creation?  
A. Vague tone  
B. Specific audience  
C. No format  
D. Negative constraints  

**Answer:** B  
**Short Explanation:** Specifying the audience ensures relevant, targeted content.

---

## MCQ 39
**Question:** What is essential for code generation prompts?  
A. High temperature  
B. Specific requirements  
C. No examples  
D. Vague language  

**Answer:** B  
**Short Explanation:** Specific requirements (e.g., language, functionality) ensure accurate code.

---

## MCQ 40
**Question:** What does RAG prioritize in context engineering?  
A. Random data  
B. Relevant, newest passages  
C. Full documents  
D. Old data  

**Answer:** B  
**Short Explanation:** RAG retrieves relevant, up-to-date passages to ground responses.

---

## MCQ 41
**Question:** How does RAG combine with prompts?  
A. Prompts for knowledge, context for behavior  
B. Prompts for behavior, context for knowledge  
C. Prompts replace context  
D. Context eliminates prompts  

**Answer:** B  
**Short Explanation:** Prompts guide behavior; context provides grounding knowledge.

---

## MCQ 42
**Question:** What is a key agent component for external interaction?  
A. Model  
B. Tools  
C. Memory  
D. Guardrails  

**Answer:** B  
**Short Explanation:** Tools enable API calls and integrations for external systems.

---

## MCQ 43
**Question:** What is the role of guardrails in AI agents?  
A. Increase randomness  
B. Ensure safety and compliance  
C. Reduce token usage  
D. Generate creative outputs  

**Answer:** B  
**Short Explanation:** Guardrails enforce safety and compliance (e.g., redacting data).

---

## MCQ 44
**Question:** What does orchestration handle in AI agents?  
A. Model training  
B. Deployment and monitoring  
C. Prompt creation  
D. Image generation  

**Answer:** B  
**Short Explanation:** Orchestration manages deployment, monitoring, and performance tracking.

---

## MCQ 45
**Question:** What is a strategy for context engineering?  
A. Overload with data  
B. Compress context  
C. Avoid tools  
D. Use vague prompts  

**Answer:** B  
**Short Explanation:** Compressing context (e.g., summarizing) optimizes token usage.

---

## MCQ 46
**Question:** What is the first step in the 6-Step Framework?  
A. Context  
B. Command  
C. Logic  
D. Roleplay  

**Answer:** B  
**Short Explanation:** Command starts with strong action verbs to guide the task.

---

## MCQ 47
**Question:** What does the Rule of Three provide in the 6-Step Framework?  
A. Output format  
B. Context structure  
C. Reasoning steps  
D. Guardrails  

**Answer:** B  
**Short Explanation:** The Rule of Three (who/what/when) structures context effectively.

---

## MCQ 48
**Question:** What is the purpose of the Questions step in the 6-Step Framework?  
A. Set tone  
B. Iterative refinement  
C. Define format  
D. Assign role  

**Answer:** B  
**Short Explanation:** Questions allow iterative refinement until AI responses stabilize.

---

## MCQ 49
**Question:** When should extensive context be used in the 6-Step Framework?  
A. Simple tasks  
B. Complex tasks  
C. Creative tasks  
D. Image generation  

**Answer:** B  
**Short Explanation:** Complex tasks require detailed context for accuracy.

---

## MCQ 50
**Question:** What is a common mistake in the 6-Step Framework?  
A. Using specific verbs  
B. Vague commands  
C. Structured outputs  
D. Few-shot examples  

**Answer:** B  
**Short Explanation:** Vague commands lead to unpredictable outputs.

---

## MCQ 51
**Question:** What is a core principle of AI image generation prompting?  
A. Vague descriptions  
B. Specificity over generality  
C. No environment cues  
D. Conflicting styles  

**Answer:** B  
**Short Explanation:** Specificity ensures clear, accurate image outputs.

---

## MCQ 52
**Question:** What is the first element in the Nano Banana image prompt structure?  
A. Lighting  
B. Subject  
C. Environment  
D. Mood  

**Answer:** B  
**Short Explanation:** Subject anchors the image prompt for clarity.

---

## MCQ 53
**Question:** Which lens is best for portrait photography in image prompts?  
A. 35mm  
B. 50mm  
C. 85mm  
D. 200mm  

**Answer:** C  
**Short Explanation:** 85mm lenses are ideal for portraits due to flattering perspective.

---

## MCQ 54
**Question:** What does f/1.4 aperture achieve in image prompts?  
A. Deep focus  
B. Shallow depth of field  
C. Wide angle  
D. Long exposure  

**Answer:** B  
**Short Explanation:** f/1.4 creates a shallow depth of field, isolating the subject.

---

## MCQ 55
**Question:** What is Rembrandt lighting in image prompts?  
A. Flat lighting  
B. Soft shadow on one cheek  
C. Harsh direct light  
D. Backlit subject  

**Answer:** B  
**Short Explanation:** Rembrandt lighting creates a soft shadow on one cheek for dramatic effect.

---

## MCQ 56
**Question:** What is a best practice for image generation prompts?  
A. Vague styles  
B. Use professional photography terms  
C. Avoid environment details  
D. Skip mood specification  

**Answer:** B  
**Short Explanation:** Professional terms (e.g., “85mm, f/1.4”) enhance realism.

---

## MCQ 57
**Question:** Which style is suitable for LinkedIn headshots?  
A. Creative/artistic  
B. Corporate/professional  
C. Fashion/editorial  
D. Lifestyle  

**Answer:** B  
**Short Explanation:** Corporate style is formal, suitable for LinkedIn.

---

## MCQ 58
**Question:** What is a common mistake in image generation prompts?  
A. Specifying lighting  
B. Conflicting styles  
C. Using examples  
D. Defining mood  

**Answer:** B  
**Short Explanation:** Conflicting styles (e.g., “corporate but artistic”) confuse the model.

---

## MCQ 59
**Question:** What should be anchored in image prompts for consistency?  
A. Background  
B. Subject  
C. Lighting  
D. Mood  

**Answer:** B  
**Short Explanation:** Anchoring the subject (e.g., “of the uploaded photo”) ensures consistency.

---

## MCQ 60
**Question:** What is a quality control checklist item for image prompts?  
A. Vague subject  
B. Specify lighting direction  
C. Avoid technical specs  
D. Skip environment  

**Answer:** B  
**Short Explanation:** Specifying lighting direction ensures clear image outputs.

---

## MCQ 61
**Question:** Which model is speculated to use MoE architecture?  
A. Claude 4  
B. ChatGPT (GPT-5)  
C. Gemini 1.0  
D. Grok 3  

**Answer:** B  
**Short Explanation:** ChatGPT (GPT-5) is speculated to use MoE for efficiency.

---

## MCQ 62
**Question:** Which model is confirmed to use a dense architecture?  
A. Gemini 2.5 Pro  
B. Grok 4  
C. Claude 4  
D. ChatGPT  

**Answer:** C  
**Short Explanation:** Claude 4 uses a dense transformer, not MoE.

---

## MCQ 63
**Question:** What is a key benefit of context engineering for agents?  
A. Reduces model size  
B. Enables autonomous scenarios  
C. Increases randomness  
D. Eliminates prompts  

**Answer:** B  
**Short Explanation:** Context engineering enables agents to handle multiple scenarios autonomously.

---

## MCQ 64
**Question:** What is the role of memory in AI agents?  
A. External interaction  
B. Dynamic conversation history  
C. Model selection  
D. Output formatting  

**Answer:** B  
**Short Explanation:** Memory stores dynamic conversation history for context retention.

---

## MCQ 65
**Question:** What is a strategy for multi-agent systems?  
A. Avoid context sharing  
B. Split tasks between agents  
C. Use single prompts  
D. High temperature  

**Answer:** B  
**Short Explanation:** Splitting tasks (e.g., search + summarize) enhances efficiency in multi-agent systems.

---

## MCQ 66
**Question:** What is a purpose of context compression?  
A. Increase token usage  
B. Optimize token efficiency  
C. Add ambiguity  
D. Reduce accuracy  

**Answer:** B  
**Short Explanation:** Compression (e.g., summarizing) fits context within token limits.

---

## MCQ 67
**Question:** What is a key component of RAG in context engineering?  
A. Random data retrieval  
B. Semantic chunking  
C. Full document loading  
D. No deduping  

**Answer:** B  
**Short Explanation:** Semantic chunking ensures relevant, manageable data retrieval.

---

## MCQ 68
**Question:** What is a common failure mode in MoE models?  
A. Perfect routing  
B. Routing instability  
C. Low token usage  
D. No specialization  

**Answer:** B  
**Short Explanation:** Routing instability can lead to incorrect expert selection in MoE.

---

## MCQ 69
**Question:** What is a recommended practice for MoE prompting?  
A. Use high temperature  
B. Avoid examples  
C. Front-load domain signals  
D. Vague terms  

**Answer:** C  
**Short Explanation:** Domain signals activate relevant experts in MoE models.

---

## MCQ 70
**Question:** What is the purpose of the Logic step in the 6-Step Framework?  
A. Assign persona  
B. Define reasoning/output format  
C. Provide context  
D. Ask questions  

**Answer:** B  
**Short Explanation:** Logic specifies reasoning steps and output structure (e.g., JSON).

---

## MCQ 71
**Question:** What is a key element for customer feedback analysis prompts?  
A. Vague themes  
B. Sentiment extraction  
C. No recommendations  
D. High temperature  

**Answer:** B  
**Short Explanation:** Sentiment extraction is critical for feedback analysis.

---

## MCQ 72
**Question:** What is a common pitfall in context engineering?  
A. Structured prompts  
B. Overloading with data  
C. Using guardrails  
D. Compressing context  

**Answer:** B  
**Short Explanation:** Overloading data causes context rot, degrading performance.

---

## MCQ 73
**Question:** Which model supports Thinking Mode for enhanced reasoning?  
A. ChatGPT  
B. Gemini  
C. Claude  
D. Grok  

**Answer:** D  
**Short Explanation:** Grok’s Thinking Mode enhances step-by-step reasoning.

---

## MCQ 74
**Question:** What is a key practice for image generation quality control?  
A. Skip mood specification  
B. Define environment details  
C. Use vague styles  
D. Avoid lighting  

**Answer:** B  
**Short Explanation:** Environment details ensure clear, relevant image backgrounds.

---

## MCQ 75
**Question:** What is the role of knowledge in AI agents?  
A. Dynamic history  
B. Static information databases  
C. External interaction  
D. Output formatting  

**Answer:** B  
**Short Explanation:** Knowledge provides static data (e.g., policy documents) for grounding.

---

## MCQ 76
**Question:** What is a benefit of few-shot prompting?  
A. No examples needed  
B. Establishes patterns  
C. Increases randomness  
D. Reduces context  

**Answer:** B  
**Short Explanation:** Few-shot prompting uses examples to establish output patterns.

---

## MCQ 77
**Question:** What is a key metric for prompt evaluation?  
A. Model size  
B. Completeness  
C. Token limit  
D. Temperature  

**Answer:** B  
**Short Explanation:** Completeness ensures outputs meet all requirements.

---

## MCQ 78
**Question:** What is a strategy for long-horizon tasks in context engineering?  
A. Load full context upfront  
B. Periodic context compaction  
C. Avoid tools  
D. High temperature  

**Answer:** B  
**Short Explanation:** Compaction summarizes history to fit token limits.

---

## MCQ 79
**Question:** What is a common mistake in image generation prompts?  
A. Specifying pose  
B. Overcomplicating prompts  
C. Using examples  
D. Defining style  

**Answer:** B  
**Short Explanation:** Overcomplicating prompts confuses the model, leading to errors.

---

## MCQ 80
**Question:** What is the purpose of Step-Back prompting?  
A. Direct answers  
B. General question first  
C. Multiple outputs  
D. Image generation  

**Answer:** B  
**Short Explanation:** Step-Back starts with a general question to contextualize complex tasks.

---

## MCQ 81
**Question:** Which model is best for safe, professional outputs?  
A. ChatGPT  
B. Gemini  
C. Claude  
D. Grok  

**Answer:** C  
**Short Explanation:** Claude’s safety-focused design excels in professional outputs.

---

## MCQ 82
**Question:** What is a key practice for MoE prompting in Grok?  
A. High temperature  
B. Use Thinking Mode  
C. Avoid role prompts  
D. Vague terms  

**Answer:** B  
**Short Explanation:** Thinking Mode enhances reasoning for MoE expert activation.

---

## MCQ 83
**Question:** What is a key component of the 6-Step Framework’s Context step?  
A. Output format  
B. Rule of Three  
C. Reasoning steps  
D. Guardrails  

**Answer:** B  
**Short Explanation:** The Rule of Three (who/what/when) structures context.

---

## MCQ 84
**Question:** What is a benefit of RAG in context engineering?  
A. Increases hallucinations  
B. Reduces token usage  
C. Eliminates prompts  
D. Adds ambiguity  

**Answer:** B  
**Short Explanation:** RAG retrieves relevant data, optimizing token efficiency.

---

## MCQ 85
**Question:** What is a common failure mode in image generation?  
A. Clear subject  
B. Conflicting styles  
C. Specific lighting  
D. Defined mood  

**Answer:** B  
**Short Explanation:** Conflicting styles (e.g., “corporate but cinematic”) confuse the model.

---

## MCQ 86
**Question:** What is a key practice for testing prompts?  
A. Avoid A/B testing  
B. Record prompt versions  
C. Use high temperature  
D. Skip metrics  

**Answer:** B  
**Short Explanation:** Recording versions tracks performance and improvements.

---

## MCQ 87
**Question:** What is a key element for code generation prompts?  
A. Vague requirements  
B. Specific examples  
C. No format  
D. High temperature  

**Answer:** B  
**Short Explanation:** Specific examples guide accurate code generation.

---

## MCQ 88
**Question:** What is a strategy for multi-agent context sharing?  
A. Avoid sharing context  
B. Share context between agents  
C. Use single agents  
D. High token usage  

**Answer:** B  
**Short Explanation:** Sharing context ensures coordinated multi-agent performance.

---

## MCQ 89
**Question:** What is a key practice for image generation prompts?  
A. Skip technical specs  
B. Use photography terminology  
C. Vague environment  
D. No mood  

**Answer:** B  
**Short Explanation:** Photography terms (e.g., “f/1.4”) enhance realism.

---

## MCQ 90
**Question:** What is a common pitfall in the 6-Step Framework?  
A. Using specific verbs  
B. Generic information  
C. Structured outputs  
D. Iterative questions  

**Answer:** B  
**Short Explanation:** Generic information leads to irrelevant outputs.

---

## MCQ 91
**Question:** What is the purpose of system prompting?  
A. Retrieve data  
B. Set behavior guidelines  
C. Define output format  
D. Assign tools  

**Answer:** B  
**Short Explanation:** System prompting sets guidelines for LLM behavior.

---

## MCQ 92
**Question:** What is a key benefit of context engineering?  
A. Increases randomness  
B. Enables complex workflows  
C. Reduces model size  
D. Eliminates prompts  

**Answer:** B  
**Short Explanation:** Context engineering supports multi-step, autonomous workflows.

---

## MCQ 93
**Question:** Which configuration is best for balanced outputs?  
A. Temperature 0, Top-P 0.9  
B. Temperature 0.5, Top-P 0.95  
C. Temperature 0.9, Top-K 40  
D. Temperature 0.1, Top-K 20  

**Answer:** B  
**Short Explanation:** Moderate temperature (0.5) and Top-P (0.95) balance consistency and diversity.

---

## MCQ 94
**Question:** What is a key metric for prompt evaluation?  
A. Token limit  
B. Accuracy  
C. Model size  
D. Temperature  

**Answer:** B  
**Short Explanation:** Accuracy ensures outputs are correct and relevant.

---

## MCQ 95
**Question:** What is a strategy for context engineering in long tasks?  
A. Load all data upfront  
B. Just-in-time retrieval  
C. Avoid compression  
D. High temperature  

**Answer:** B  
**Short Explanation:** Just-in-time retrieval fetches relevant data dynamically, saving tokens.

---

## MCQ 96
**Question:** What is a key component of AI agents for safety?  
A. Model  
B. Tools  
C. Guardrails  
D. Memory  

**Answer:** C  
**Short Explanation:** Guardrails enforce safety and compliance.

---

## MCQ 97
**Question:** What is a common mistake in image generation prompts?  
A. Specifying pose  
B. Missing lighting details  
C. Using examples  
D. Defining style  

**Answer:** B  
**Short Explanation:** Missing lighting details leads to unclear image outputs.

---

## MCQ 98
**Question:** What is a benefit of few-shot examples in MoE models?  
A. Increases randomness  
B. Guides expert routing  
C. Reduces context  
D. Adds ambiguity  

**Answer:** B  
**Short Explanation:** Few-shot examples align MoE routing with the task domain.

---

## MCQ 99
**Question:** What is the purpose of the Roleplay step in the 6-Step Framework?  
A. Define output format  
B. Specify expertise  
C. Provide context  
D. Ask questions  

**Answer:** B  
**Short Explanation:** Roleplay assigns a specific expertise (e.g., “HR expert”) to guide responses.

---

## MCQ 100
**Question:** What is a key practice for RAG optimization?  
A. Load full documents  
B. Optimize chunking  
C. Avoid deduping  
D. High token usage  

**Answer:** B  
**Short Explanation:** Optimized chunking (e.g., 500-token segments) ensures relevant data retrieval.

---

## MCQ 101
**Question:** Which model is best for multimodal tasks?  
A. Claude  
B. Gemini  
C. Grok  
D. ChatGPT  

**Answer:** B  
**Short Explanation:** Gemini’s confirmed multimodal capabilities excel in text and image tasks.

---

## MCQ 102
**Question:** What is a key practice for prompt chaining?  
A. Use single prompts  
B. Break tasks into steps  
C. Avoid examples  
D. High temperature  

**Answer:** B  
**Short Explanation:** Breaking tasks into steps ensures clarity and manageability.

---

## MCQ 103
**Question:** What is a common failure mode in MoE models?  
A. Perfect recall  
B. Memory overhead  
C. Low token usage  
D. No specialization  

**Answer:** B  
**Short Explanation:** MoE models may face memory overhead due to expert routing.

---

## MCQ 104
**Question:** What is a key element for content creation prompts?  
A. Vague tone  
B. Specific format  
C. No audience  
D. Negative constraints  

**Answer:** B  
**Short Explanation:** Specific formats (e.g., blog post, report) ensure usable outputs.

---

## MCQ 105
**Question:** What is a strategy for context isolation?  
A. Mix all data  
B. Separate user preferences  
C. Avoid memory  
D. High token usage  

**Answer:** B  
**Short Explanation:** Isolating user preferences from task data maintains clarity.

---

## MCQ 106
**Question:** What is a benefit of the Questions step in the 6-Step Framework?  
A. Reduces context  
B. Refines outputs iteratively  
C. Sets tone  
D. Defines format  

**Answer:** B  
**Short Explanation:** Questions allow iterative refinement for tailored outputs.

---

## MCQ 107
**Question:** What is a key practice for image generation prompts?  
A. Skip technical specs  
B. Specify mood  
C. Vague environment  
D. Avoid lighting  

**Answer:** B  
**Short Explanation:** Specifying mood ensures the desired emotional tone in images.

---

## MCQ 108
**Question:** What is a common pitfall in context engineering?  
A. Using guardrails  
B. Overloading with data  
C. Compressing context  
D. Structured prompts  

**Answer:** B  
**Short Explanation:** Overloading data causes context rot, degrading performance.

---

## MCQ 109
**Question:** What is a key metric for evaluating image generation prompts?  
A. Token limit  
B. Style adherence  
C. Model size  
D. Temperature  

**Answer:** B  
**Short Explanation:** Style adherence ensures images match the intended aesthetic.

---

## MCQ 110
**Question:** What is a strategy for multi-agent systems?  
A. Avoid context sharing  
B. Use specialized agents  
C. Single agent for all tasks  
D. High temperature  

**Answer:** B  
**Short Explanation:** Specialized agents (e.g., search, summarize) enhance efficiency.

---

## MCQ 111
**Question:** What is a key practice for MoE prompting in Gemini?  
A. Vague terms  
B. Low temperature  
C. No examples  
D. High token usage  

**Answer:** B  
**Short Explanation:** Low temperature (e.g., 0.1) stabilizes expert routing in Gemini.

---

## MCQ 112
**Question:** What is a key component of the Nano Banana structure?  
A. Vague subject  
B. Lighting  
C. No environment  
D. Random style  

**Answer:** B  
**Short Explanation:** Lighting is a critical component for realistic image prompts.

---

## MCQ 113
**Question:** What is a benefit of context engineering for agents?  
A. Increases hallucinations  
B. Maintains consistency  
C. Reduces model size  
D. Eliminates prompts  

**Answer:** B  
**Short Explanation:** Context engineering ensures consistent outputs across scenarios.

---

## MCQ 114
**Question:** What is a common failure mode in long conversations?  
A. Perfect recall  
B. Context rot  
C. Structured outputs  
D. Low token usage  

**Answer:** B  
**Short Explanation:** Context rot degrades performance as the context window grows.

---

## MCQ 115
**Question:** What is a key practice for RAG in context engineering?  
A. Load full documents  
B. Dedupe retrieved data  
C. Avoid chunking  
D. High token usage  

**Answer:** B  
**Short Explanation:** Deduping ensures unique, relevant data retrieval.

---

## MCQ 116
**Question:** What is a key element for customer feedback analysis prompts?  
A. Vague themes  
B. Actionable recommendations  
C. No sentiment  
D. High temperature  

**Answer:** B  
**Short Explanation:** Actionable recommendations provide practical insights.

---

## MCQ 117
**Question:** What is a common mistake in the 6-Step Framework?  
A. Using specific verbs  
B. Skipping the Questions step  
C. Structured outputs  
D. Few-shot examples  

**Answer:** B  
**Short Explanation:** Skipping Questions misses iterative refinement opportunities.

---

## MCQ 118
**Question:** What is a benefit of MoE architecture for prompting?  
A. Increased memory usage  
B. Specialization for tasks  
C. Slower processing  
D. No routing  

**Answer:** B  
**Short Explanation:** MoE’s specialization enhances task-specific performance.

---

## MCQ 119
**Question:** What is a key practice for image generation quality control?  
A. Vague subject  
B. Specify technical specs  
C. Avoid lighting  
D. Skip mood  

**Answer:** B  
**Short Explanation:** Technical specs (e.g., “85mm, f/1.4”) ensure realistic images.

---

## MCQ 120
**Question:** What is the purpose of the Formatting step in the 6-Step Framework?  
A. Assign persona  
B. Structure outputs  
C. Provide context  
D. Ask questions  

**Answer:** B  
**Short Explanation:** Formatting ensures usable, structured outputs (e.g., tables).

---

## MCQ 121
**Question:** What is a key practice for prompt testing?  
A. Avoid A/B testing  
B. Use metrics like accuracy  
C. High temperature  
D. Skip versioning  

**Answer:** B  
**Short Explanation:** Metrics like accuracy evaluate prompt effectiveness.

---

## MCQ 122
**Question:** What is a common pitfall in MoE prompting?  
A. Domain-specific signals  
B. Vague prompts  
C. Low temperature  
D. Few-shot examples  

**Answer:** B  
**Short Explanation:** Vague prompts cause routing instability in MoE models.

---

## MCQ 123
**Question:** What is a key element for code generation prompts?  
A. Vague requirements  
B. Specific language  
C. No examples  
D. High temperature  

**Answer:** B  
**Short Explanation:** Specifying the programming language ensures accurate code.

---

## MCQ 124
**Question:** What is a strategy for context engineering in agents?  
A. Load all data upfront  
B. Just-in-time retrieval  
C. Avoid compression  
D. High token usage  

**Answer:** B  
**Short Explanation:** Just-in-time retrieval optimizes token efficiency.

---

## MCQ 125
**Question:** What is a benefit of the 6-Step Framework?  
A. Increases ambiguity  
B. Transforms interactions into expert consultations  
C. Reduces context  
D. Adds randomness  

**Answer:** B  
**Short Explanation:** The framework ensures expert-level, tailored outputs.

---

## MCQ 126
**Question:** What is a key component of the Nano Banana structure?  
A. Vague subject  
B. Environment  
C. No lighting  
D. Random style  

**Answer:** B  
**Short Explanation:** Environment details ensure relevant image backgrounds.

---

## MCQ 127
**Question:** What is a key practice for RAG optimization?  
A. Load full documents  
B. Prioritize newest passages  
C. Avoid deduping  
D. High token usage  

**Answer:** B  
**Short Explanation:** Prioritizing newest passages ensures relevance.

---

## MCQ 128
**Question:** What is a common failure mode in image generation?  
A. Clear subject  
B. Missing environment details  
C. Specific lighting  
D. Defined mood  

**Answer:** B  
**Short Explanation:** Missing environment details leads to unclear backgrounds.

---

## MCQ 129
**Question:** What is a key practice for MoE prompting in ChatGPT?  
A. Vague terms  
B. Separate mixed tasks  
C. High temperature  
D. No examples  

**Answer:** B  
**Short Explanation:** Separating mixed tasks prevents expert oscillation.

---

## MCQ 130
**Question:** What is a key element for content creation prompts?  
A. Vague audience  
B. Specific tone  
C. No format  
D. Negative constraints  

**Answer:** B  
**Short Explanation:** Specific tone ensures appropriate content style.

---

## MCQ 131
**Question:** What is a common pitfall in context engineering?  
A. Using guardrails  
B. Overloading with constraints  
C. Compressing context  
D. Structured prompts  

**Answer:** B  
**Short Explanation:** Overloading constraints confuses the agent.

---

## MCQ 132
**Question:** What is a key metric for evaluating prompt outputs?  
A. Token limit  
B. Format adherence  
C. Model size  
D. Temperature  

**Answer:** B  
**Short Explanation:** Format adherence ensures outputs match the desired structure.

---

## MCQ 133
**Question:** What is a strategy for multi-agent systems?  
A. Avoid context sharing  
B. Use sub-agents for deep dives  
C. Single agent for all tasks  
D. High temperature  

**Answer:** B  
**Short Explanation:** Sub-agents handle specialized tasks efficiently.

---

## MCQ 134
**Question:** What is a key practice for image generation prompts?  
A. Skip technical specs  
B. Use professional photography terms  
C. Vague environment  
D. Avoid lighting  

**Answer:** B  
**Short Explanation:** Photography terms enhance image realism.

---

## MCQ 135
**Question:** What is a common mistake in the 6-Step Framework?  
A. Using specific verbs  
B. Skipping the Logic step  
C. Structured outputs  
D. Few-shot examples  

**Answer:** B  
**Short Explanation:** Skipping Logic leads to unclear reasoning and outputs.

---

## MCQ 136
**Question:** What is a benefit of MoE architecture for prompting?  
A. Increased memory usage  
B. Efficiency through specialization  
C. Slower processing  
D. No routing  

**Answer:** B  
**Short Explanation:** MoE’s specialization enhances task efficiency.

---

## MCQ 137
**Question:** What is a key practice for image generation quality control?  
A. Vague subject  
B. Specify pose  
C. Avoid lighting  
D. Skip mood  

**Answer:** B  
**Short Explanation:** Specifying pose ensures clear subject positioning.

---

## MCQ 138
**Question:** What is the purpose of the Context step in the 6-Step Framework?  
A. Define output format  
B. Provide background information  
C. Assign persona  
D. Ask questions  

**Answer:** B  
**Short Explanation:** Context provides background (e.g., who/what/when) for grounding.

---

## MCQ 139
**Question:** What is a benefit of RAG in context engineering?  
A. Increases hallucinations  
B. Reduces hallucinations  
C. Eliminates prompts  
D. Adds ambiguity  

**Answer:** B  
**Short Explanation:** RAG grounds responses with relevant data, reducing hallucinations.

---

## MCQ 140
**Question:** What is a common failure mode in MoE models?  
A. Perfect recall  
B. Routing errors  
C. Low token usage  
D. No specialization  

**Answer:** B  
**Short Explanation:** Routing errors cause incorrect expert selection in MoE.

---

## MCQ 141
**Question:** What is a key practice for prompt testing?  
A. Avoid A/B testing  
B. Use metrics like completeness  
C. High temperature  
D. Skip versioning  

**Answer:** B  
**Short Explanation:** Completeness ensures all requirements are met.

---

## MCQ 142
**Question:** What is a common pitfall in MoE prompting?  
A. Domain-specific signals  
B. High temperature  
C. Low temperature  
D. Few-shot examples  

**Answer:** B  
**Short Explanation:** High temperature causes routing instability in MoE models.

---

## MCQ 143
**Question:** What is a key element for code generation prompts?  
A. Vague requirements  
B. Specific functionality  
C. No examples  
D. High temperature  

**Answer:** B  
**Short Explanation:** Specific functionality ensures accurate code outputs.

---

## MCQ 144
**Question:** What is a strategy for context engineering in agents?  
A. Load all data upfront  
B. Context isolation  
C. Avoid compression  
D. High token usage  

**Answer:** B  
**Short Explanation:** Isolating context (e.g., user preferences) maintains clarity.

---

## MCQ 145
**Question:** What is a benefit of the 6-Step Framework?  
A. Increases ambiguity  
B. Enhances output quality  
C. Reduces context  
D. Adds randomness  

**Answer:** B  
**Short Explanation:** The framework ensures high-quality, tailored outputs.

---

## MCQ 146
**Question:** What is a key component of the Nano Banana structure?  
A. Vague subject  
B. Mood  
C. No lighting  
D. Random style  

**Answer:** B  
**Short Explanation:** Mood ensures the desired emotional tone in images.

---

## MCQ 147
**Question:** What is a key practice for RAG optimization?  
A. Load full documents  
B. Optimize ranking  
C. Avoid deduping  
D. High token usage  

**Answer:** B  
**Short Explanation:** Optimized ranking prioritizes relevant data.

---

## MCQ 148
**Question:** What is a common failure mode in image generation?  
A. Clear subject  
B. Overcomplicating prompts  
C. Specific lighting  
D. Defined mood  

**Answer:** B  
**Short Explanation:** Overcomplicating prompts confuses the model.

---

## MCQ 149
**Question:** What is a key practice for MoE prompting in Grok?  
A. Vague terms  
B. Use few-shot examples  
C. High temperature  
D. No role prompts  

**Answer:** B  
**Short Explanation:** Few-shot examples guide expert routing in Grok.

---

## MCQ 150
**Question:** What is a key element for content creation prompts?  
A. Vague audience  
B. Specific topic  
C. No format  
D. Negative constraints  

**Answer:** B  
**Short Explanation:** Specific topics ensure focused content.

---

## MCQ 151
**Question:** What is a common pitfall in context engineering?  
A. Using guardrails  
B. Overloading with data  
C. Compressing context  
D. Structured prompts  

**Answer:** B  
**Short Explanation:** Overloading data causes context rot.

---

## MCQ 152
**Question:** What is a key metric for evaluating prompt outputs?  
A. Token limit  
B. Consistency  
C. Model size  
D. Temperature  

**Answer:** B  
**Short Explanation:** Consistency ensures reliable outputs across runs.

---

## MCQ 153
**Question:** What is a strategy for multi-agent systems?  
A. Avoid context sharing  
B. Use coordinator agents  
C. Single agent for all tasks  
D. High temperature  

**Answer:** B  
**Short Explanation:** Coordinator agents manage specialized sub-agents.

---

## MCQ 154
**Question:** What is a key practice for image generation prompts?  
A. Skip technical specs  
B. Specify style  
C. Vague environment  
D. Avoid lighting  

**Answer:** B  
**Short Explanation:** Specifying style ensures the desired aesthetic.

---

## MCQ 155
**Question:** What is a common mistake in the 6-Step Framework?  
A. Using specific verbs  
B. Skipping the Roleplay step  
C. Structured outputs  
D. Few-shot examples  

**Answer:** B  
**Short Explanation:** Skipping Roleplay misses expertise guidance.

---

## MCQ 156
**Question:** What is a benefit of MoE architecture for prompting?  
A. Increased memory usage  
B. Scalability through specialization  
C. Slower processing  
D. No routing  

**Answer:** B  
**Short Explanation:** MoE’s scalability enhances task-specific performance.

---

## MCQ 157
**Question:** What is a key practice for image generation quality control?  
A. Vague subject  
B. Specify environment  
C. Avoid lighting  
D. Skip mood  

**Answer:** B  
**Short Explanation:** Environment details ensure relevant backgrounds.

---

## MCQ 158
**Question:** What is the purpose of the Command step in the 6-Step Framework?  
A. Define output format  
B. Guide the task with action verbs  
C. Provide context  
D. Ask questions  

**Answer:** B  
**Short Explanation:** Command uses action verbs to guide the task clearly.

---

## MCQ 159
**Question:** What is a benefit of RAG in context engineering?  
A. Increases hallucinations  
B. Optimizes token usage  
C. Eliminates prompts  
D. Adds ambiguity  

**Answer:** B  
**Short Explanation:** RAG optimizes token usage with relevant data.

---

## MCQ 160
**Question:** What is a common failure mode in MoE models?  
A. Perfect recall  
B. Expert oscillation  
C. Low token usage  
D. No specialization  

**Answer:** B  
**Short Explanation:** Expert oscillation occurs when tasks are mixed, causing routing issues.

---

## MCQ 161
**Question:** What is a key practice for prompt testing?  
A. Avoid A/B testing  
B. Use metrics like style  
C. High temperature  
D. Skip versioning  

**Answer:** B  
**Short Explanation:** Style metrics ensure outputs match the desired tone.

---

## MCQ 162
**Question:** What is a common pitfall in MoE prompting?  
A. Domain-specific signals  
B. Mixed tasks  
C. Low temperature  
D. Few-shot examples  

**Answer:** B  
**Short Explanation:** Mixed tasks cause expert oscillation in MoE models.

---

## MCQ 163
**Question:** What is a key element for code generation prompts?  
A. Vague requirements  
B. Specific examples  
C. No format  
D. High temperature  

**Answer:** B  
**Short Explanation:** Specific examples guide accurate code generation.

---

## MCQ 164
**Question:** What is a strategy for context engineering in agents?  
A. Load all data upfront  
B. Context summarization  
C. Avoid compression  
D. High token usage  

**Answer:** B  
**Short Explanation:** Summarization optimizes token efficiency.

---

## MCQ 165
**Question:** What is a benefit of the 6-Step Framework?  
A. Increases ambiguity  
B. Ensures structured outputs  
C. Reduces context  
D. Adds randomness  

**Answer:** B  
**Short Explanation:** The framework ensures clear, structured outputs.

---

## MCQ 166
**Question:** What is a key component of the Nano Banana structure?  
A. Vague subject  
B. Technical specs  
C. No lighting  
D. Random style  

**Answer:** B  
**Short Explanation:** Technical specs (e.g., “f/1.4”) ensure realistic images.

---

## MCQ 167
**Question:** What is a key practice for RAG optimization?  
A. Load full documents  
B. Optimize token budgets  
C. Avoid deduping  
D. High token usage  

**Answer:** B  
**Short Explanation:** Token budgets ensure efficient data retrieval.

---

## MCQ 168
**Question:** What is a common failure mode in image generation?  
A. Clear subject  
B. Vague pose  
C. Specific lighting  
D. Defined mood  

**Answer:** B  
**Short Explanation:** Vague pose leads to unclear subject positioning.

---

## MCQ 169
**Question:** What is a key practice for MoE prompting in Gemini?  
A. Vague terms  
B. Use domain-specific vocabulary  
C. High temperature  
D. No examples  

**Answer:** B  
**Short Explanation:** Domain-specific vocabulary guides expert routing.

---

## MCQ 170
**Question:** What is a key element for content creation prompts?  
A. Vague audience  
B. Specific format  
C. No tone  
D. Negative constraints  

**Answer:** B  
**Short Explanation:** Specific formats ensure usable content outputs.

---

## MCQ 171
**Question:** What is a common pitfall in context engineering?  
A. Using guardrails  
B. Overloading with constraints  
C. Compressing context  
D. Structured prompts  

**Answer:** B  
**Short Explanation:** Overloading constraints confuses the agent.

---

## MCQ 172
**Question:** What is a key metric for evaluating prompt outputs?  
A. Token limit  
B. Style adherence  
C. Model size  
D. Temperature  

**Answer:** B  
**Short Explanation:** Style adherence ensures outputs match the desired tone.

---

## MCQ 173
**Question:** What is a strategy for multi-agent systems?  
A. Avoid context sharing  
B. Use specialized sub-agents  
C. Single agent for all tasks  
D. High temperature  

**Answer:** B  
**Short Explanation:** Specialized sub-agents enhance task efficiency.

---

## MCQ 174
**Question:** What is a key practice for image generation prompts?  
A. Skip technical specs  
B. Specify lighting direction  
C. Vague environment  
D. Avoid mood  

**Answer:** B  
**Short Explanation:** Lighting direction ensures clear image outputs.

---

## MCQ 175
**Question:** What is a common mistake in the 6-Step Framework?  
A. Using specific verbs  
B. Skipping the Formatting step  
C. Structured outputs  
D. Few-shot examples  

**Answer:** B  
**Short Explanation:** Skipping Formatting leads to unusable outputs.

---

## MCQ 176
**Question:** What is a benefit of MoE architecture for prompting?  
A. Increased memory usage  
B. Efficiency through sparse activation  
C. Slower processing  
D. No routing  

**Answer:** B  
**Short Explanation:** Sparse activation enhances efficiency in MoE models.

---

## MCQ 177
**Question:** What is a key practice for image generation quality control?  
A. Vague subject  
B. Specify mood  
C. Avoid lighting  
D. Skip environment  

**Answer:** B  
**Short Explanation:** Mood ensures the desired emotional tone.

---

## MCQ 178
**Question:** What is the purpose of the Questions step in the 6-Step Framework?  
A. Define output format  
B. Iterative refinement  
C. Provide context  
D. Assign persona  

**Answer:** B  
**Short Explanation:** Questions refine outputs iteratively for accuracy.

---

## MCQ 179
**Question:** What is a benefit of RAG in context engineering?  
A. Increases hallucinations  
B. Enhances accuracy  
C. Eliminates prompts  
D. Adds ambiguity  

**Answer:** B  
**Short Explanation:** RAG enhances accuracy with relevant data.

---

## MCQ 180
**Question:** What is a common failure mode in MoE models?  
A. Perfect recall  
B. Memory overhead  
C. Low token usage  
D. No specialization  

**Answer:** B  
**Short Explanation:** Memory overhead can occur due to expert routing.

---

## MCQ 181
**Question:** What is a key practice for prompt testing?  
A. Avoid A/B testing  
B. Use metrics like relevance  
C. High temperature  
D. Skip versioning  

**Answer:** B  
**Short Explanation:** Relevance ensures outputs align with intent.

---

## MCQ 182
**Question:** What is a common pitfall in MoE prompting?  
A. Domain-specific signals  
B. Vague prompts  
C. Low temperature  
D. Few-shot examples  

**Answer:** B  
**Short Explanation:** Vague prompts cause routing instability in MoE models.

---

## MCQ 183
**Question:** What is a key element for code generation prompts?  
A. Vague requirements  
B. Specific language  
C. No examples  
D. High temperature  

**Answer:** B  
**Short Explanation:** Specific language ensures accurate code outputs.

---

## MCQ 184
**Question:** What is a strategy for context engineering in agents?  
A. Load all data upfront  
B. Context compression  
C. Avoid tools  
D. High token usage  

**Answer:** B  
**Short Explanation:** Compression optimizes token efficiency.

---

## MCQ 185
**Question:** What is a benefit of the 6-Step Framework?  
A. Increases ambiguity  
B. Enhances output clarity  
C. Reduces context  
D. Adds randomness  

**Answer:** B  
**Short Explanation:** The framework ensures clear, actionable outputs.

---

## MCQ 186
**Question:** What is a key component of the Nano Banana structure?  
A. Vague subject  
B. Style  
C. No lighting  
D. Random mood  

**Answer:** B  
**Short Explanation:** Style ensures the desired aesthetic in images.

---

## MCQ 187
**Question:** What is a key practice for RAG optimization?  
A. Load full documents  
B. Optimize deduping  
C. Avoid chunking  
D. High token usage  

**Answer:** B  
**Short Explanation:** Deduping ensures unique, relevant data.

---

## MCQ 188
**Question:** What is a common failure mode in image generation?  
A. Clear subject  
B. Vague lighting  
C. Specific pose  
D. Defined mood  

**Answer:** B  
**Short Explanation:** Vague lighting leads to unclear image outputs.

---

## MCQ 189
**Question:** What is a key practice for MoE prompting in ChatGPT?  
A. Vague terms  
B. Use low temperature  
C. High token usage  
D. No examples  

**Answer:** B  
**Short Explanation:** Low temperature stabilizes expert routing in ChatGPT.

---

## MCQ 190
**Question:** What is a key element for content creation prompts?  
A. Vague audience  
B. Specific audience  
C. No format  
D. Negative constraints  

**Answer:** B  
**Short Explanation:** Specific audience ensures targeted content.

---

## MCQ 191
**Question:** What is a common pitfall in context engineering?  
A. Using guardrails  
B. Overloading with data  
C. Compressing context  
D. Structured prompts  

**Answer:** B  
**Short Explanation:** Overloading data causes context rot.

---

## MCQ 192
**Question:** What is a key metric for evaluating prompt outputs?  
A. Token limit  
B. Accuracy  
C. Model size  
D. Temperature  

**Answer:** B  
**Short Explanation:** Accuracy ensures correct outputs.

---

## MCQ 193
**Question:** What is a strategy for multi-agent systems?  
A. Avoid context sharing  
B. Use coordinator agents  
C. Single agent for all tasks  
D. High temperature  

**Answer:** B  
**Short Explanation:** Coordinator agents manage specialized sub-agents.

---

## MCQ 194
**Question:** What is a key practice for image generation prompts?  
A. Skip technical specs  
B. Specify pose  
C. Vague environment  
D. Avoid lighting  

**Answer:** B  
**Short Explanation:** Specifying pose ensures clear subject positioning.

---

## MCQ 195
**Question:** What is a common mistake in the 6-Step Framework?  
A. Using specific verbs  
B. Skipping the Context step  
C. Structured outputs  
D. Few-shot examples  

**Answer:** B  
**Short Explanation:** Skipping Context leads to ungrounded outputs.

---

## MCQ 196
**Question:** What is a benefit of MoE architecture for prompting?  
A. Increased memory usage  
B. Specialization for tasks  
C. Slower processing  
D. No routing  

**Answer:** B  
**Short Explanation:** Specialization enhances task-specific performance.

---

## MCQ 197
**Question:** What is a key practice for image generation quality control?  
A. Vague subject  
B. Specify technical specs  
C. Avoid lighting  
D. Skip mood  

**Answer:** B  
**Short Explanation:** Technical specs ensure realistic images.

---

## MCQ 198
**Question:** What is the purpose of the Roleplay step in the 6-Step Framework?  
A. Define output format  
B. Specify expertise  
C. Provide context  
D. Ask questions  

**Answer:** B  
**Short Explanation:** Roleplay assigns expertise for tailored responses.

---

## MCQ 199
**Question:** What is a benefit of RAG in context engineering?  
A. Increases hallucinations  
B. Enhances relevance  
C. Eliminates prompts  
D. Adds ambiguity  

**Answer:** B  
**Short Explanation:** RAG enhances relevance with targeted data retrieval.

---

## MCQ 200
**Question:** What is a common failure mode in MoE models?  
A. Perfect recall  
B. Routing instability  
C. Low token usage  
D. No specialization  

**Answer:** B  
**Short Explanation:** Routing instability causes inconsistent expert selection.

---

## Study Tips
- **Practice Testing**: Use Grok (grok.com), ChatGPT ([platform.openai.com](https://platform.openai.com/)), Gemini ([aistudio.google.com](https://aistudio.google.com/)), and Claude ([console.anthropic.com](https://console.anthropic.com/)) to test prompts and configurations.
- **Memorize Key Concepts**: Focus on distinctions (prompt vs. context engineering, MoE vs. dense), photography terms (e.g., 85mm, f/1.4), and agent components.
- **Analyze Examples**: Review syllabus examples (e.g., ReAct, Nano Banana) and rewrite weak prompts.
- **Build Templates**: Create reusable prompt templates for common tasks (e.g., feedback analysis, image generation).
- **Use Checklists**: Ensure prompts include all key elements (e.g., subject, lighting, format).
- **Review Resources**: Study Anthropic’s context engineering article and LangChain guides for deeper insights.